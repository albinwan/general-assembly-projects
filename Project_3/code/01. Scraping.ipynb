{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reddit has gained tremondously popularity recently. A recent article on [The Verge](https://www.theverge.com/2020/12/1/21754984/reddit-dau-daily-users-revealed) revealed that Reddit now has 52 million users registered (that's about 9 times of Singapore's population!), and this was recorded before the /rwallstreetbets saga that happened in the summer of 2021. Due to the popularity of Reddit of late, it would be interesting to experiment and design a Machine Learning model that is able to predict and classify posts against two subreddits. This project aims to classify posts between subreddits of r/GainIt and r/LoseIt. r/GainIt is a subreddit where people share on different ways to bulk up weight as well as success stories on how they did it. r/LoseIt is the opposite where people share on weight loss. Whether you're on whose looking for the right 'keywords' to use in your Reddit post, or simply just trying to play around with Machine Learning models to predict classifications, this model should be of interest to you.\n",
    "\n",
    "The key question is this: **What are the key words one should use in a Reddit post body so that it can distintictly classify itself in either r/LoseIt or r/GainIt?**\n",
    "\n",
    "Due to the nature of the topics, one can imagine that the contents are likely to be very identical with each other between the two subreddits. Despite this, the model that was designed performed well with an accuracy score of more than 92%. Baseline accuracy score to beat is 50%. This project has showed that utilizing bag-of-words vectorizing techniques like CountVectorizer/TfidfVectorizer along with Logistical Regression as well as Naive Bayes Classifier was effective despite the similarities between the two subreddits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease of readability, this project is split into 4 workbooks:\n",
    "\n",
    "1. Scraping (`01. Scraping.ipynb`)\n",
    "2. Data Cleaning (`02. Data Cleaning.ipynb`)\n",
    "3. EDA (`03. EDA.ipynb`)\n",
    "4. Modelling (`04. Modelling.ipynb`)\n",
    "\n",
    "`01. Scraping.ipynb`\n",
    "This part of the workbook entails the usage of for loops to iterate through .json files directly from Reddit. I managed to scrape about 700 posts per subreddit, giving me a total of about 1,400 posts. As these two subreddits were very text-based, I was able to obtain a good amount of dataset to run my model on.\n",
    "\n",
    "`02. Data Cleaning.ipynb`\n",
    "Data cleaning involves taking the raw form of the Reddit scrape and putting them through various streams of text cleansing including lemmatizing, removal of special characters and digits as well as stop words removal. Lemmatizing was found to be more effective than Porter Stemmer's approach hence the use of it.\n",
    "\n",
    "`03. EDA.ipynb`\n",
    "Here I do some exploratory data analysis to see if there are any interesting observations. You can find plots of top word counts that appeared in either subreddits as well as word clouds to visualize this as well.\n",
    "\n",
    "`04. Modelling.ipynb`\n",
    "This part covers the actual modelling aspects of this project. Modelling include the use of bag-of-words techniques (Count Vectorizer and TF-IDF Vectorizer) to vectorize the words, and using multiple classifier models (Logistic Regression, Multinomial Naive Bayes and Random Forest Classifier) to test and see which is the most effective model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Reddit Scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section includes the codes for scraping from two subreddits, /rGainIt and /rLoseIt. We simply use a for loop to iterate through all of Reddit's posts and extend them into a single list. We also include the use of a random user-agent name generator to prevent Reddit from blocking us during the web scrapping process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a user-agent name generator to prevent Reddit from blocking web scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_generator():\n",
    "    letters = string.ascii_lowercase\n",
    "    return (''.join(random.choice(letters) for i in range(9)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to scrape from Reddit and export into .csv file. Function takes in URL link, number of times to scrape (note that you get 25 posts per scrape). I scrapped through the main subreddit and it's 'new' section in order to obtain more rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_reddit(url, count_of_scrape, filename):\n",
    "    results = []\n",
    "    after = None\n",
    "    \n",
    "    for a in range(count_of_scrape):\n",
    "        if after == None:\n",
    "            current_url = url\n",
    "        else:\n",
    "            current_url = url + '?after=' + after\n",
    "        print(current_url)\n",
    "        res = requests.get(current_url, headers={'User-agent': name_generator()})\n",
    "\n",
    "        if res.status_code != 200:\n",
    "            print('Status error', res.status_code)\n",
    "            break\n",
    "\n",
    "        current_dict = res.json()\n",
    "        current_posts = [p['data'] for p in current_dict['data']['children']]\n",
    "        results.extend(current_posts)\n",
    "        after = current_dict['data']['after']\n",
    "    results = pd.DataFrame(results)\n",
    "    results.to_csv('../datasets/'+filename, index=False)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reddit.com/r/gainit.json\n",
      "https://www.reddit.com/r/gainit.json?after=t3_m4c0un\n",
      "https://www.reddit.com/r/gainit.json?after=t3_m1nu7s\n",
      "https://www.reddit.com/r/gainit.json?after=t3_lz6t31\n",
      "https://www.reddit.com/r/gainit.json?after=t3_lxx9kl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>saved</th>\n",
       "      <th>mod_reason_title</th>\n",
       "      <th>gilded</th>\n",
       "      <th>clicked</th>\n",
       "      <th>title</th>\n",
       "      <th>link_flair_richtext</th>\n",
       "      <th>...</th>\n",
       "      <th>permalink</th>\n",
       "      <th>parent_whitelist_status</th>\n",
       "      <th>stickied</th>\n",
       "      <th>url</th>\n",
       "      <th>subreddit_subscribers</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>num_crossposts</th>\n",
       "      <th>media</th>\n",
       "      <th>is_video</th>\n",
       "      <th>link_flair_template_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>gainit</td>\n",
       "      <td>**Welcome to the weekly stupid questions threa...</td>\n",
       "      <td>t2_6l4z3</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[Mod] Simple Questions - the weekly stupid que...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/gainit/comments/m5j4gj/mod_simple_questions...</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.reddit.com/r/gainit/comments/m5j4g...</td>\n",
       "      <td>308755</td>\n",
       "      <td>1.615810e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>gainit</td>\n",
       "      <td>Good morning everyone!\\n\\nThird week! Here we ...</td>\n",
       "      <td>t2_2pz9dpsj</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>The Gainit Program Party - 5/3/1 BBB Beefcake ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/gainit/comments/m5jg9i/the_gainit_program_p...</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.reddit.com/r/gainit/comments/m5jg9...</td>\n",
       "      <td>308755</td>\n",
       "      <td>1.615811e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>c08085c4-3cc0-11e4-92c2-12313d16464b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>gainit</td>\n",
       "      <td>http://imgur.com/a/GowELgh\\n\\nExactly two year...</td>\n",
       "      <td>t2_16zgu6</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[Progress] - Two years, 25kg gained. 19/6'4/100kg</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/gainit/comments/m5pvg4/progress_two_years_2...</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.reddit.com/r/gainit/comments/m5pvg...</td>\n",
       "      <td>308755</td>\n",
       "      <td>1.615829e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>gainit</td>\n",
       "      <td>i either have insomnia or DSPD, basically i us...</td>\n",
       "      <td>t2_4gn6rlq3</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>how many of you have sleep disorders ?</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/gainit/comments/m5id3k/how_many_of_you_have...</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.reddit.com/r/gainit/comments/m5id3...</td>\n",
       "      <td>308755</td>\n",
       "      <td>1.615807e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>gainit</td>\n",
       "      <td>https://imgur.com/gallery/1QoYqRa\\n\\nI’ll try ...</td>\n",
       "      <td>t2_16xhmr</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Feeling Directionless (nutrition/Cals)</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/gainit/comments/m6165f/feeling_directionles...</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.reddit.com/r/gainit/comments/m6165...</td>\n",
       "      <td>308755</td>\n",
       "      <td>1.615870e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>None</td>\n",
       "      <td>gainit</td>\n",
       "      <td>I’m training for a 5k right now so my emphasis...</td>\n",
       "      <td>t2_1cjvuxse</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2 Day Push/Pull + 1 Full</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/gainit/comments/lwepo2/2_day_pushpull_1_full/</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.reddit.com/r/gainit/comments/lwepo...</td>\n",
       "      <td>308755</td>\n",
       "      <td>1.614725e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>None</td>\n",
       "      <td>gainit</td>\n",
       "      <td>Like for example, following PHAT:\\n\\n* Dumbbel...</td>\n",
       "      <td>t2_8apfe</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Exercise order and hypertrophy, does it matter...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/gainit/comments/lw0r1h/exercise_order_and_h...</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.reddit.com/r/gainit/comments/lw0r1...</td>\n",
       "      <td>308755</td>\n",
       "      <td>1.614688e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>None</td>\n",
       "      <td>gainit</td>\n",
       "      <td></td>\n",
       "      <td>t2_3rdqewr5</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>I am currently 6’3 185 and I’m planning to bul...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/gainit/comments/lwhief/i_am_currently_63_18...</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.reddit.com/r/gainit/comments/lwhie...</td>\n",
       "      <td>308755</td>\n",
       "      <td>1.614734e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>None</td>\n",
       "      <td>gainit</td>\n",
       "      <td>[PHAT](https://simplyshredded.com/mega-feature...</td>\n",
       "      <td>t2_6bmrcwal</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Going to start PHAT again, but some of the exe...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/gainit/comments/lwhdx2/going_to_start_phat_...</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.reddit.com/r/gainit/comments/lwhdx...</td>\n",
       "      <td>308755</td>\n",
       "      <td>1.614733e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>None</td>\n",
       "      <td>gainit</td>\n",
       "      <td>I weigh 140lbs at 5’10 and I’m currently 19 ye...</td>\n",
       "      <td>t2_10u5xx</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Is my current calorie intake and diet good to ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/gainit/comments/lwn5mo/is_my_current_calori...</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.reddit.com/r/gainit/comments/lwn5m...</td>\n",
       "      <td>308755</td>\n",
       "      <td>1.614753e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    approved_at_utc subreddit  \\\n",
       "0              None    gainit   \n",
       "1              None    gainit   \n",
       "2              None    gainit   \n",
       "3              None    gainit   \n",
       "4              None    gainit   \n",
       "..              ...       ...   \n",
       "122            None    gainit   \n",
       "123            None    gainit   \n",
       "124            None    gainit   \n",
       "125            None    gainit   \n",
       "126            None    gainit   \n",
       "\n",
       "                                              selftext author_fullname  saved  \\\n",
       "0    **Welcome to the weekly stupid questions threa...        t2_6l4z3  False   \n",
       "1    Good morning everyone!\\n\\nThird week! Here we ...     t2_2pz9dpsj  False   \n",
       "2    http://imgur.com/a/GowELgh\\n\\nExactly two year...       t2_16zgu6  False   \n",
       "3    i either have insomnia or DSPD, basically i us...     t2_4gn6rlq3  False   \n",
       "4    https://imgur.com/gallery/1QoYqRa\\n\\nI’ll try ...       t2_16xhmr  False   \n",
       "..                                                 ...             ...    ...   \n",
       "122  I’m training for a 5k right now so my emphasis...     t2_1cjvuxse  False   \n",
       "123  Like for example, following PHAT:\\n\\n* Dumbbel...        t2_8apfe  False   \n",
       "124                                                        t2_3rdqewr5  False   \n",
       "125  [PHAT](https://simplyshredded.com/mega-feature...     t2_6bmrcwal  False   \n",
       "126  I weigh 140lbs at 5’10 and I’m currently 19 ye...       t2_10u5xx  False   \n",
       "\n",
       "    mod_reason_title  gilded  clicked  \\\n",
       "0               None       0    False   \n",
       "1               None       0    False   \n",
       "2               None       0    False   \n",
       "3               None       0    False   \n",
       "4               None       0    False   \n",
       "..               ...     ...      ...   \n",
       "122             None       0    False   \n",
       "123             None       0    False   \n",
       "124             None       0    False   \n",
       "125             None       0    False   \n",
       "126             None       0    False   \n",
       "\n",
       "                                                 title link_flair_richtext  \\\n",
       "0    [Mod] Simple Questions - the weekly stupid que...                  []   \n",
       "1    The Gainit Program Party - 5/3/1 BBB Beefcake ...                  []   \n",
       "2    [Progress] - Two years, 25kg gained. 19/6'4/100kg                  []   \n",
       "3               how many of you have sleep disorders ?                  []   \n",
       "4               Feeling Directionless (nutrition/Cals)                  []   \n",
       "..                                                 ...                 ...   \n",
       "122                           2 Day Push/Pull + 1 Full                  []   \n",
       "123  Exercise order and hypertrophy, does it matter...                  []   \n",
       "124  I am currently 6’3 185 and I’m planning to bul...                  []   \n",
       "125  Going to start PHAT again, but some of the exe...                  []   \n",
       "126  Is my current calorie intake and diet good to ...                  []   \n",
       "\n",
       "     ...                                          permalink  \\\n",
       "0    ...  /r/gainit/comments/m5j4gj/mod_simple_questions...   \n",
       "1    ...  /r/gainit/comments/m5jg9i/the_gainit_program_p...   \n",
       "2    ...  /r/gainit/comments/m5pvg4/progress_two_years_2...   \n",
       "3    ...  /r/gainit/comments/m5id3k/how_many_of_you_have...   \n",
       "4    ...  /r/gainit/comments/m6165f/feeling_directionles...   \n",
       "..   ...                                                ...   \n",
       "122  ...   /r/gainit/comments/lwepo2/2_day_pushpull_1_full/   \n",
       "123  ...  /r/gainit/comments/lw0r1h/exercise_order_and_h...   \n",
       "124  ...  /r/gainit/comments/lwhief/i_am_currently_63_18...   \n",
       "125  ...  /r/gainit/comments/lwhdx2/going_to_start_phat_...   \n",
       "126  ...  /r/gainit/comments/lwn5mo/is_my_current_calori...   \n",
       "\n",
       "     parent_whitelist_status  stickied  \\\n",
       "0                    all_ads      True   \n",
       "1                    all_ads      True   \n",
       "2                    all_ads     False   \n",
       "3                    all_ads     False   \n",
       "4                    all_ads     False   \n",
       "..                       ...       ...   \n",
       "122                  all_ads     False   \n",
       "123                  all_ads     False   \n",
       "124                  all_ads     False   \n",
       "125                  all_ads     False   \n",
       "126                  all_ads     False   \n",
       "\n",
       "                                                   url  subreddit_subscribers  \\\n",
       "0    https://www.reddit.com/r/gainit/comments/m5j4g...                 308755   \n",
       "1    https://www.reddit.com/r/gainit/comments/m5jg9...                 308755   \n",
       "2    https://www.reddit.com/r/gainit/comments/m5pvg...                 308755   \n",
       "3    https://www.reddit.com/r/gainit/comments/m5id3...                 308755   \n",
       "4    https://www.reddit.com/r/gainit/comments/m6165...                 308755   \n",
       "..                                                 ...                    ...   \n",
       "122  https://www.reddit.com/r/gainit/comments/lwepo...                 308755   \n",
       "123  https://www.reddit.com/r/gainit/comments/lw0r1...                 308755   \n",
       "124  https://www.reddit.com/r/gainit/comments/lwhie...                 308755   \n",
       "125  https://www.reddit.com/r/gainit/comments/lwhdx...                 308755   \n",
       "126  https://www.reddit.com/r/gainit/comments/lwn5m...                 308755   \n",
       "\n",
       "      created_utc  num_crossposts media  is_video  \\\n",
       "0    1.615810e+09               0  None     False   \n",
       "1    1.615811e+09               0  None     False   \n",
       "2    1.615829e+09               0  None     False   \n",
       "3    1.615807e+09               0  None     False   \n",
       "4    1.615870e+09               0  None     False   \n",
       "..            ...             ...   ...       ...   \n",
       "122  1.614725e+09               0  None     False   \n",
       "123  1.614688e+09               0  None     False   \n",
       "124  1.614734e+09               0  None     False   \n",
       "125  1.614733e+09               0  None     False   \n",
       "126  1.614753e+09               0  None     False   \n",
       "\n",
       "                   link_flair_template_id  \n",
       "0                                     NaN  \n",
       "1    c08085c4-3cc0-11e4-92c2-12313d16464b  \n",
       "2                                     NaN  \n",
       "3                                     NaN  \n",
       "4                                     NaN  \n",
       "..                                    ...  \n",
       "122                                   NaN  \n",
       "123                                   NaN  \n",
       "124                                   NaN  \n",
       "125                                   NaN  \n",
       "126                                   NaN  \n",
       "\n",
       "[127 rows x 103 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_reddit('https://www.reddit.com/r/gainit.json', 20, 'gainit_raw.csv')\n",
    "scrape_reddit('https://www.reddit.com/r/gainit/new.json', 20, 'gainit_raw2.csv')\n",
    "scrape_reddit('https://www.reddit.com/r/loseit.json', 20, 'loseit_raw.csv')\n",
    "scrape_reddit('https://www.reddit.com/r/loseit/new.json', 20, 'loseit_raw2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
